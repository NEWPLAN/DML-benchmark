# DML-benchmark
NASP DML benchmark for automaticlly topology searching


## Roadmap of experiment

### part1:先测单项的比较： 
	##### A：网络开销：
		1:启动开销测量与分析
			实验方法：发送等量数据块（通过网络传输的整体数据量一致：1M*256 vs 256M*1），包含不同启动次数，观察整体传输完成时间
			状态：已完成；
			计划：或许还可以再反复测量一下，变换数据块大小和轮数，使得结果更明确
		2:n-vs-n 通信incast问题与分析带宽下降原因
			实验方法：不停发送等大小的msg （default：16K*128，尝试改变一下？），观测接受端的吞吐变化（1G/10G/40G/100G）；
			挑战：100Gbps下的 1-vs-1双向带宽不满问题（待解决）
			状态：目前已完成第一阶段（基于DCQCN的CC）
			计划：关闭ECN，启用PFC实现流量管理，再测量一下
		3:1-vs-n接收数据时的blocking waiting开销
			实验方法：发送等大小（1K, 10K, ..., 100M）msg，统计收齐所有子节点发过来的数据的时间开销；
			难点：没办法保证同时发送数据，时钟同步问题（us级别）
			状态：代码部分需要修改（poll-cq部分逻辑）
			计划：//修改为epoll方法非阻塞查询完成队列，发送指定数据量 （未来再说）
		4:分阶段同步，耦合开销（端到端的只评估网络的开销）：
			实验方法：
				a: 变换深度（1-16）（ring），两个点之间传输等大小msg，统计时间；
				b: 变换宽度（1-16）（PS），多个点之间传输统计时间；
				要求: 每次传输的数据块1M/10M/100M是固定的，达到公平对比的要求。
			状态：未测
			计划：TBA
	##### B：merge开销：
		分析了解不同数据块merge的效率问题 （基本完成，2-16块数据）
			1.1: 固定每个数据块大小，单次合并不同数量的数据块的效率分析（SIMD/cache的原因）
				实验方法：变换数据块个数，观察完成合并的时间开销
				状态：基本实验结果已经得出，但是展示的是单位加法的时间开销（保留）
				计划：绘出（16个节点）完整merge的整体时间开销（接下来）
				目的：评估SIMD/cache带来的好处
			1.2:变换数据块的大小，测试merge的效率 （选取典型的数据块个数：2/4/8/16）
				实验方法：变换数据块大小，观察完成合并的时间开销
				状态：基本测试（1K-100M）单个数据块的大小
				计划：绘出（16个节点）完整merge的整体时间开销（接下来）
### Part2:不同拓扑下的端到端的AllReduce benchmark实验：
	实验方法：包含16个节点不同拓扑下的AllReduce时间开销对比（网络利用率）
	状态：缺少butterfly/HD模型，目前缺少broadcast的阶段
	提升：进一步完善以上要求。

